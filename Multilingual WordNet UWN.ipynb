{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "README\n",
    "\n",
    "UWN 2010-10\n",
    "Gerard de Melo\n",
    "http://www.mpi-inf.mpg.de/yago-naga/uwn/\n",
    "\n",
    "\n",
    "== DESCRIPTION ==\n",
    "\n",
    "UWN is an automatically constructed multilingual lexical knowledge base\n",
    "based on the structure of Princeton WordNet. Please see the web site above\n",
    "for more information.\n",
    "\n",
    "UWN is best used in conjunction with the original WordNet created at\n",
    "at Princeton University. \n",
    "http://wordnet.princeton.edu\n",
    "\n",
    "\n",
    "== DATA FORMAT ==\n",
    "\n",
    "The gzip-compressed TSV file is best decompressed on the fly\n",
    "while reading for best performance. Each line contains subject, predicate,\n",
    "object, and weight, separated by tabs.\n",
    "Words and other terms are listed as \"t/<iso-639-3-language-code>/<string>\", e.g.\n",
    "\"t/eng/house\" for the English term \"house\".\n",
    "Predicates include \"rel:means\" for the relationship between a term and its meanings.\n",
    "WordNet senses are given as \"s/<wordnet-pos-tag><wordnet-3.0-synset-offset>\"\n",
    "(e.g. \"s/n1740\" for WordNet 3.0's entity synset).\n",
    "\n",
    "\n",
    "== CREDITS AND LICENSE ==\n",
    "\n",
    "Gerard de Melo\n",
    "http://icsi.berkeley.edy/~demelo/\n",
    "\n",
    "For academic use, please cite:\n",
    "Gerard de Melo and Gerhard Weikum (2009). Towards a Universal Wordnet by Learning from Combined Evidence.\n",
    "In: Proc. 18th ACM Conference on Information and Knowledge Management (CIKM 2009),\n",
    "Hong Kong, China. ACM, New York, USA.\n",
    "\n",
    "License: CC BY-NC-SA 3.0\n",
    "http://creativecommons.org/licenses/by-nc-sa/3.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./wordnet/data/uwn-dump_201012.tsv', delimiter='\\t', header=None, names=['subject', 'predicate', 'object', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t/xmf/ბულგარულ</td>\n",
       "      <td>rel:means</td>\n",
       "      <td>language/bul</td>\n",
       "      <td>1.187343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t/xmf/ბულგარულ</td>\n",
       "      <td>rel:means</td>\n",
       "      <td>s/n9695620</td>\n",
       "      <td>1.224455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t/xmf/ინგლისურ</td>\n",
       "      <td>rel:means</td>\n",
       "      <td>s/n6155432</td>\n",
       "      <td>0.938639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t/xmf/ინგლისურ</td>\n",
       "      <td>rel:means</td>\n",
       "      <td>s/n6947032</td>\n",
       "      <td>1.220780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t/xmf/ფრანგულ</td>\n",
       "      <td>rel:means</td>\n",
       "      <td>language/fra</td>\n",
       "      <td>1.337511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  predicate        object    weight\n",
       "0  t/xmf/ბულგარულ  rel:means  language/bul  1.187343\n",
       "1  t/xmf/ბულგარულ  rel:means    s/n9695620  1.224455\n",
       "2  t/xmf/ინგლისურ  rel:means    s/n6155432  0.938639\n",
       "3  t/xmf/ინგლისურ  rel:means    s/n6947032  1.220780\n",
       "4   t/xmf/ფრანგულ  rel:means  language/fra  1.337511"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = df[df.subject.str.startswith('t/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets = df[df.subject.str.startswith('s/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rel:means    1848113\n",
       "Name: predicate, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms.predicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rel:lexicalization    1810685\n",
       "Name: predicate, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets.predicate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure what weight means... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/tha/รัสเซีย</td>\n",
       "      <td>0.703229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/tur/Rusya Federasyonu</td>\n",
       "      <td>0.730033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/arb/روسيا</td>\n",
       "      <td>0.763194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/ara/روسيا</td>\n",
       "      <td>0.707933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/vol/Rusän</td>\n",
       "      <td>0.763194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/lfn/Rusia</td>\n",
       "      <td>0.763194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/ind/Rusia</td>\n",
       "      <td>0.733253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/pes/روسیه</td>\n",
       "      <td>0.763194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/hun/Oroszország</td>\n",
       "      <td>0.735622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/lit/Rusijos Federacija</td>\n",
       "      <td>0.730033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/rus/Российская Федерация</td>\n",
       "      <td>0.864462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/rus/Россия</td>\n",
       "      <td>0.809144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/ina/Russia</td>\n",
       "      <td>0.736904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/dan/Rusland</td>\n",
       "      <td>0.718382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/mar/रशिया</td>\n",
       "      <td>0.736904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/ell/Ρωσία</td>\n",
       "      <td>0.707049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/ces/Rusko</td>\n",
       "      <td>0.705554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/eus/Errusia</td>\n",
       "      <td>0.718382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/fin/Venäjä</td>\n",
       "      <td>0.707531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>s/n9002814</td>\n",
       "      <td>rel:lexicalization</td>\n",
       "      <td>t/cat/Rússia</td>\n",
       "      <td>0.730555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject           predicate                      object    weight\n",
       "13  s/n9002814  rel:lexicalization               t/tha/รัสเซีย  0.703229\n",
       "14  s/n9002814  rel:lexicalization     t/tur/Rusya Federasyonu  0.730033\n",
       "15  s/n9002814  rel:lexicalization                 t/arb/روسيا  0.763194\n",
       "16  s/n9002814  rel:lexicalization                 t/ara/روسيا  0.707933\n",
       "17  s/n9002814  rel:lexicalization                 t/vol/Rusän  0.763194\n",
       "18  s/n9002814  rel:lexicalization                 t/lfn/Rusia  0.763194\n",
       "19  s/n9002814  rel:lexicalization                 t/ind/Rusia  0.733253\n",
       "20  s/n9002814  rel:lexicalization                 t/pes/روسیه  0.763194\n",
       "21  s/n9002814  rel:lexicalization           t/hun/Oroszország  0.735622\n",
       "22  s/n9002814  rel:lexicalization    t/lit/Rusijos Federacija  0.730033\n",
       "23  s/n9002814  rel:lexicalization  t/rus/Российская Федерация  0.864462\n",
       "24  s/n9002814  rel:lexicalization                t/rus/Россия  0.809144\n",
       "25  s/n9002814  rel:lexicalization                t/ina/Russia  0.736904\n",
       "26  s/n9002814  rel:lexicalization               t/dan/Rusland  0.718382\n",
       "27  s/n9002814  rel:lexicalization                 t/mar/रशिया  0.736904\n",
       "28  s/n9002814  rel:lexicalization                 t/ell/Ρωσία  0.707049\n",
       "29  s/n9002814  rel:lexicalization                 t/ces/Rusko  0.705554\n",
       "30  s/n9002814  rel:lexicalization               t/eus/Errusia  0.718382\n",
       "31  s/n9002814  rel:lexicalization                t/fin/Venäjä  0.707531\n",
       "32  s/n9002814  rel:lexicalization                t/cat/Rússia  0.730555"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_language(x):\n",
    "    split = x.split('/')\n",
    "    lan = split[1]\n",
    "    return lan\n",
    "\n",
    "def extract_term(x):\n",
    "    split = x.split('/')\n",
    "    term = split[2]\n",
    "    return term\n",
    "\n",
    "def extract_synset(x):\n",
    "    split = x.split('/')\n",
    "    synset = split[1]\n",
    "    return synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = terms[terms.object.str.startswith('s/')]\n",
    "terms.loc[:, 'term'] = terms.subject.apply(extract_term)\n",
    "terms.loc[:, 'lan'] = terms.subject.apply(extract_language)\n",
    "terms.loc[:, 'synset'] = terms.object.apply(extract_synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = terms.drop(['subject', 'predicate', 'object'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n9007723    4\n",
       "n9010300    1\n",
       "n9002814    1\n",
       "n9008454    1\n",
       "n9002630    1\n",
       "Name: synset, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[t.term == 'Russia'].synset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
